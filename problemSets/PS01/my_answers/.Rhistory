# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c(),  pkgTest)
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
set.seed(123)
# create empirical distribution of observed data
ECDF <- ecdf(data)
set.seed(123)
data<-rcauchy(1000, location = 0, scale = 1)
# create empirical distribution of observed data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
print(D)
ks_result <- ks.test(data, "pnorm", mean = mean(data), sd = sd(data))
View(ks_result)
print(ks_result)
ks_p_value <- 2 * pnorm(ks_result * sqrt((n_x * n_y) / (n_x + n_y))) - 1
ks_p_value <- 2 * pnorm(ks_result * sqrt(length(data))) - 1
print(ks_result)
ks_p_value <- 2 * pnorm(ks_result * sqrt(length(data))) - 1
ks_p_value <- 2 * pnorm(ks_result * sqrt(length(data))) - 1
ks_p_value <- 2 * pnorm(ks_result * sqrt(length(data))) - 1
n_x <- length(data)
ks_p_value <- 2 * pnorm(ks_result * sqrt(length(data))) - 1
n_x <- length(data)
ks_p_value <- 2 * pnorm(ks_result * sqrt(n_x)) - 1
sqrt(n_x)
ks_result
ks_p_value <- 2 * pnorm(D * sqrt(n_x)) - 1
ks_p_value
n_x <- length(data)
ks_result <- ks.test(data, "pnorm", mean = mean(data), sd = sd(data))
print(ks_result)
ks_p_value <- 2 * pnorm(ks_result * sqrt(n_x)) - 1
ks_p_value <- 2 * pnorm(D * sqrt(n_x)) - 1
ks_p_value <- 1-(2 * pnorm(D * sqrt(n_x)) - 1)
ks_p_value <- (2 * pnorm(D * sqrt(n_x)) - 1)
ks_p_value <- 1-(2 * pnorm(D * sqrt(n_x)) - 1)
ks_p_value <- (2 * pnorm(D * sqrt(n_x)) - 1)
ks_p_value <- (2 * pnorm(D * sqrt(n_x)) - 1)-1
1-ks_p_value
print(ks_p_value)
ks_p_value <- (2 * pnorm(D * sqrt(n_x)) - 1)
print(ks_p_value)
1-ks_p_value
print(ks_result)
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("us_tweets.csv",
stringsAsFactors=FALSE,
encoding = "utf-8")
set.seed (123)
data <- data.frame(x = runif(200, 1, 10))
data$y <- 0 + 2.75*data$x + rnorm(200, 0, 1.5)
set.seed (123)
data <- data.frame(x = runif(200, 1, 10))
data$y <- 0 + 2.75*data$x + rnorm(200, 0, 1.5)
ols_bfgs <- optim(par = c(0, 0), fn = function(beta) {
sum((data$y - (beta[1] + beta[2] * data$x))^2)
}, method = "BFGS")
ols_bfgs
lm_model <- lm(y ~ x, data = data)
lm_model
ols_bfgs_ori <- optim(fn=linear.lik,par=c(1,1,1),hessian=TRUE,y=data$y,X=cbind(1,data$x),method="BFGS")
ols_bfgs_ori <- optim(fn=linear,par=c(1,1,1),hessian=TRUE,y=data$y,X=cbind(1,data$x),method="BFGS")
linear.lik <- function(beta, y, X) {
# Compute the negative log-likelihood for OLS
resid <- y - X %*% beta
lik <- sum(resid^2)
return(lik)
}
ols_bfgs_ori <- optim(fn=linear.lik,par=c(1,1,1),hessian=TRUE,y=data$y,X=cbind(1,data$x),method="BFGS")
ols_bfgs_ori <- optim(fn=linear.lik,par=c(1,1),hessian=TRUE,y=data$y,X=cbind(1,data$x),method="BFGS")
ols_bfgs_ori
cat("使用BFGS算法拟合OLS回归的系数:\n")
cat("截距:", ols_bfgs$par[1], "\n")
cat("斜率:", ols_bfgs$par[2], "\n")
cat("\n")
# 显示结果
cat("使用lm拟合OLS回归的系数:\n")
cat(summary(ols_lm)$coefficients[, 1], "\n")
# 比较系数
cat("\nOLS回归系数的比较:\n")
cat("截距差异:", ols_bfgs$par[1] - coef(ols_lm)[1], "\n")
cat("斜率差异:", ols_bfgs$par[2] - coef(ols_lm)[2], "\n")
ols_bfgs <- optim(fn=linear.lik,par=c(1,1),hessian=TRUE,y=data$y,X=cbind(1,data$x),method="BFGS")
ols_bfgs <- optim(fn=linear.lik,par=c(1,1),hessian=TRUE,y=data$y,X=cbind(1,data$x),method="BFGS")
cat("使用BFGS算法拟合OLS回归的系数:\n")
cat("截距:", ols_bfgs$par[1], "\n")
cat("斜率:", ols_bfgs$par[2], "\n")
cat("\n")
ols_lm <- lm(y ~ x, data = data)
ols_lm
ols_bfgs
# 显示结果
cat("使用lm拟合OLS回归的系数:\n")
cat(summary(ols_lm)$coefficients[, 1], "\n")
# 比较系数
cat("\nOLS回归系数的比较:\n")
cat("截距差异:", ols_bfgs$par[1] - coef(ols_lm)[1], "\n")
cat("斜率差异:", ols_bfgs$par[2] - coef(ols_lm)[2], "\n")
print(ks_result$p.value)
print(p)
p<-(((2*pi)**0.5)/D)*sum
set.seed(123)
data<-rcauchy(1000, location = 0, scale = 1)
# create empirical distribution of observed data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
print(D)
n <- length(data)
k=1
sum=0
pi=3.14159
e=2.71828
for (k in 1:n){
exponent<- -1*((((2*k-1)**2)*((pi)**2))/(8*(D**2)))
sum=sum+ (e**exponent)
}
p<-(((2*pi)**0.5)/D)*sum
ks_result <- ks.test(data, "pnorm", mean = mean(data), sd = sd(data))
print(ks_result$p.value)
print(p)
print(ks_result$p.value-p)
cat("截距差异:", ols_bfgs$par[1] - coef(ols_lm)[1], "\n")
cat("斜率差异:", ols_bfgs$par[2] - coef(ols_lm)[2], "\n")
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c(),  pkgTest)
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#####################
# Problem 1
#####################
# generate 1,000 Cauchy random variables
set.seed(123)
data<-rcauchy(1000, location = 0, scale = 1)
# create empirical distribution of observed data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
print(D)
# get the length of data
n <- length(data)
# set the parameters
k=1
sum=0
pi=3.14159
e=2.71828
# do a for loop according to the formula to calculate the p-value
for (k in 1:n){
exponent<- -1*((((2*k-1)**2)*((pi)**2))/(8*(D**2)))
sum=sum+ (e**exponent)
}
p<-(((2*pi)**0.5)/D)*sum
# do a KS test by R
ks_result <- ks.test(data, "pnorm", mean = mean(data), sd = sd(data))
# Compare the p-value in two results
print(ks_result$p.value)
print(p)
set.seed (123)
# Variable x: Generate 200 random numbers from a uniform distribution
data <- data.frame(x = runif(200, 1, 10))
# Variable y: Generate values based on a linear relationship
data$y <- 0 + 2.75*data$x + rnorm(200, 0, 1.5)
# Compute the negative log-likelihood for OLS
linear.lik <- function(beta, y, X) {
# Compute the residuals by subtracting the predicted values from the actual values
resid <- y - X %*% beta
# Compute the sum of squared residuals
lik <- sum(resid^2)
# Return the result
return(lik)
}
# build model by OLS regression using BFGS algorithm
ols_bfgs <- optim(fn=linear.lik,par=c(1,1),hessian=TRUE,y=data$y,X=cbind(1,data$x),method="BFGS")
cat("Coefficients using BFGS algorithm:\n")
cat("Intercept:", ols_bfgs$par[1], "\n")
cat("Slope:", ols_bfgs$par[2], "\n")
cat("\n")
# build linear model
ols_lm <- lm(y ~ x, data = data)
ols_lm
ols_bfgs
#show the result of linear model
cat("Coefficients using linear model:\n")
cat(summary(ols_lm)$coefficients[, 1], "\n")
#Compare the coefficients
cat("\nComparison in different ways of regression\n")
cat("difference in intercept:", ols_bfgs$par[1] - coef(ols_lm)[1], "\n")
cat("difference in slope:", ols_bfgs$par[2] - coef(ols_lm)[2], "\n")
ols_lm
ols_bfgs
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c(),  pkgTest)
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#####################
# Problem 1
#####################
# generate 1,000 Cauchy random variables
set.seed(123)
data<-rcauchy(1000, location = 0, scale = 1)
# create empirical distribution of observed data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
print(D)
# get the length of data
n <- length(data)
# set the parameters
k=1
sum=0
pi=3.14159
e=2.71828
# do a for loop according to the formula to calculate the p-value
for (k in 1:n){
exponent<- -1*((((2*k-1)**2)*((pi)**2))/(8*(D**2)))
sum=sum+ (e**exponent)
}
p<-(((2*pi)**0.5)/D)*sum
# do a KS test by R
ks_result <- ks.test(data, "pnorm", mean = mean(data), sd = sd(data))
# Compare the p-value in two results
print(ks_result$p.value)
print(p)
set.seed (123)
# Variable x: Generate 200 random numbers from a uniform distribution
data <- data.frame(x = runif(200, 1, 10))
# Variable y: Generate values based on a linear relationship
data$y <- 0 + 2.75*data$x + rnorm(200, 0, 1.5)
# Compute the negative log-likelihood for OLS
linear.lik <- function(beta, y, X) {
# Compute the residuals by subtracting the predicted values from the actual values
resid <- y - X %*% beta
# Compute the sum of squared residuals
lik <- sum(resid^2)
# Return the result
return(lik)
}
# build model by OLS regression using BFGS algorithm
ols_bfgs <- optim(fn=linear.lik,par=c(1,1),hessian=TRUE,y=data$y,X=cbind(1,data$x),method="BFGS")
cat("Coefficients using BFGS algorithm:\n")
cat("Intercept:", ols_bfgs$par[1], "\n")
cat("Slope:", ols_bfgs$par[2], "\n")
cat("\n")
# build linear model
ols_lm <- lm(y ~ x, data = data)
# Check the result
ols_lm
ols_bfgs
#show the result of linear model
cat("Coefficients using linear model:\n")
cat(summary(ols_lm)$coefficients[, 1], "\n")
#Compare the coefficients
cat("\nComparison in different ways of regression\n")
cat("difference in intercept:", ols_bfgs$par[1] - coef(ols_lm)[1], "\n")
cat("difference in slope:", ols_bfgs$par[2] - coef(ols_lm)[2], "\n")
